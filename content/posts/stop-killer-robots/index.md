---
title: stop killer robots
date: 2024-05-10T12:12:00.000Z
image: iai-harpy-loitering-munition-cat-uxo-002.jpg
---
I endorse the recognition that

> “Australians expect to be afforded at least the same protections available to citizens in comparable jurisdictions.”

But further: Australians would not want our country to be left behind as an under-regulated jurisdiction where objectionable implementations and applications can be developed and pursued.

I share concerns stemming from the observation, aired in the proposals paper, that

> “AI systems can make decisions autonomously and pervasively, without human intervention at any stage of the decision-making process, if designed by organisations to function that way.”

And so I note with alarm that areas of concern in civil sphere - including dehumanisation; embedding bias, discrimination and inequality; loss of transparency; and loss of accountability for automated decision-making - have direct corollaries in the military domain, where they confront fundamental responsibilities under international humanitarian law and international human rights law.

It is imperative that the elevated risks posed by AI in the military domain are granted similar scrutiny as in the civil domain.

The UN Sec Gen’s report Lethal autonomous weapons systems this year warned:

> “There is a strong sense that time is running out for the international community to take preventive action on this issue. I therefore reiterate my call for the conclusion, by 2026, of a legally binding instrument to prohibit lethal autonomous weapons systems”

Austria’s statement to the Sixth Review Conference of the Convention on Certain Conventional Weapons in December 2021 warned:

> “We are at the crossroads of crossing red lines of humans being killed by algorithms and systems that humans potentially do not even understand retrospectively”

This year, a HRC report by Special Rapporteur Morris Tidball-Binz on Autonomous weapons systems warned: 

> “The international community is crossing a threshold which may be difficult, if not impossible, to reverse later.”

The proposals paper tells us that

> “Australia proposes to align with other jurisdictions, which have treated national security and defence applications separately from civilian applications”

but offers no confidence that this approach will allow Australia to match progress on setting boundaries to military applications of AI, to that pursued in this process. Although there has been considerable discussion in international fora for the past ten years or so, little progress is evident.

Meanwhile, it is noteworthy that despite the USA claim to treat military applications separately, New York, USA, has legislated for: ‘Prohibiting robots and uncrewed aircraft equipped or mounted with weapons’ (2023 NY S 9439)

This example of regulation made ahead of any hoped international treaty development may in part be driven by recognition of the reality of proliferation. Weapons designated for militaries tend to bleed into policing. Further, there is the further risk of non-state actors gaining access.

and so, in response to the proposals paper’s questions:

I am not satisfied that the proposed principles adequately treat AI systems with risk so high as to be an outright disqualification; specifically, lethal autonomous weapons systems (LAWS).

I do not accept that defence and national security labels are sufficient to allow the weapons industry to proceed with the development of LAWS under ‘separate’ treatment. I want to see a comprehensive ban on LAWS, and in the absence of demonstrable progress I can’t accept the proposal that civil applications of GPAI should be subject to guardrails that the weapons industry are considered free to ignore.

I do recommend that government should recognise some risk as so totally unacceptable as to justify an outright ban on the developing, producing, acquiring, stockpiling, transferring, or using:

• any autonomous weapons system which includes facial recognition technologies;

• anti-personnel LAWS: ie designed to target humans directly;

• any LAWS that operate completely outside human control

I recommend that the best form for applying guardrails is via dedicated legislation. A dedicated act of parliament would maximise consistency, guarantee certainty for all domains, avoid silos and mitigate the risk of GPAI developers gaming existing frameworks by shopping around for the most convenient domain to conduct early stage development.
